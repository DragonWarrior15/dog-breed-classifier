2021-06-14 22:07:26,378 - INFO - logging to file logs/202106142207
2021-06-14 22:07:26,380 - INFO - saving models to folder models/202106142207
2021-06-14 22:07:26,381 - INFO - learning rate is 0.01
2021-06-14 22:07:26,381 - INFO - batch_size is 32
2021-06-14 22:07:26,381 - INFO - epochs is 5
2021-06-14 22:07:26,381 - INFO - input image size is 224
2021-06-14 22:07:26,381 - INFO - limit_classes is set to False
2021-06-14 22:07:26,382 - INFO - optimizer is <class 'torch.optim.adam.Adam'>
2021-06-14 22:07:26,382 - INFO - image transforms for training
 Compose(
    RandomAffine(degrees=[-15.0, 15.0], translate=(0.1, 0.1), scale=(0.9, 1.1), shear=[-10.0, 10.0])
    RandomHorizontalFlip(p=0.5)
    RandomVerticalFlip(p=0.5)
    Resize(size=(224, 224), interpolation=bilinear)
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2021-06-14 22:07:26,383 - INFO - image transforms for testing
 Compose(
    Resize(size=(224, 224), interpolation=bilinear)
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2021-06-14 22:07:27,128 - INFO - total classes are 133
2021-06-14 22:07:27,166 - INFO - dogBreedClassifier(
  (model): SqueezeNet(
    (features): Sequential(
      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))
      (1): ReLU(inplace=True)
      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (3): Fire(
        (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))
        (squeeze_activation): ReLU(inplace=True)
        (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))
        (expand1x1_activation): ReLU(inplace=True)
        (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (expand3x3_activation): ReLU(inplace=True)
      )
      (4): Fire(
        (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))
        (squeeze_activation): ReLU(inplace=True)
        (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))
        (expand1x1_activation): ReLU(inplace=True)
        (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (expand3x3_activation): ReLU(inplace=True)
      )
      (5): Fire(
        (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))
        (squeeze_activation): ReLU(inplace=True)
        (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
        (expand1x1_activation): ReLU(inplace=True)
        (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (expand3x3_activation): ReLU(inplace=True)
      )
      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (7): Fire(
        (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
        (squeeze_activation): ReLU(inplace=True)
        (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
        (expand1x1_activation): ReLU(inplace=True)
        (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (expand3x3_activation): ReLU(inplace=True)
      )
      (8): Fire(
        (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))
        (squeeze_activation): ReLU(inplace=True)
        (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
        (expand1x1_activation): ReLU(inplace=True)
        (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (expand3x3_activation): ReLU(inplace=True)
      )
      (9): Fire(
        (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
        (squeeze_activation): ReLU(inplace=True)
        (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
        (expand1x1_activation): ReLU(inplace=True)
        (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (expand3x3_activation): ReLU(inplace=True)
      )
      (10): Fire(
        (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))
        (squeeze_activation): ReLU(inplace=True)
        (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        (expand1x1_activation): ReLU(inplace=True)
        (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (expand3x3_activation): ReLU(inplace=True)
      )
      (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
      (12): Fire(
        (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
        (squeeze_activation): ReLU(inplace=True)
        (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        (expand1x1_activation): ReLU(inplace=True)
        (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (expand3x3_activation): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Conv2d(512, 133, kernel_size=(1, 1), stride=(1, 1))
      (2): ReLU(inplace=True)
      (3): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
)
2021-06-14 22:07:27,167 - INFO - Params to learn:
2021-06-14 22:07:27,168 - INFO - 	model.classifier.1.weight
2021-06-14 22:07:27,168 - INFO - 	model.classifier.1.bias
2021-06-14 22:07:27,169 - INFO - Epoch 1
-------------------------------
2021-06-14 22:07:30,347 - INFO - loss: 420.416138  [    0/ 6679]
2021-06-14 22:07:51,004 - INFO - loss: 1368.490723  [  160/ 6679]
2021-06-14 22:08:11,693 - INFO - loss: 2041.463257  [  320/ 6679]
2021-06-14 22:08:26,715 - INFO - loss: 2428.924072  [  480/ 6679]
2021-06-14 22:08:44,970 - INFO - loss: 2617.904785  [  640/ 6679]
2021-06-14 22:09:06,270 - INFO - loss: 2972.068848  [  800/ 6679]
2021-06-14 22:09:27,035 - INFO - loss: 3015.685791  [  960/ 6679]
2021-06-14 22:09:47,578 - INFO - loss: 1804.229370  [ 1120/ 6679]
2021-06-14 22:10:09,465 - INFO - loss: 1824.970825  [ 1280/ 6679]
2021-06-14 22:10:29,402 - INFO - loss: 1576.670166  [ 1440/ 6679]
2021-06-14 22:10:47,531 - INFO - loss: 2024.864258  [ 1600/ 6679]
2021-06-14 22:11:05,237 - INFO - loss: 1500.285278  [ 1760/ 6679]
2021-06-14 22:11:30,461 - INFO - loss: 1577.837402  [ 1920/ 6679]
2021-06-14 22:11:52,045 - INFO - loss: 1551.832520  [ 2080/ 6679]
2021-06-14 22:12:10,681 - INFO - loss: 1083.157959  [ 2240/ 6679]
2021-06-14 22:12:29,735 - INFO - loss: 929.382874  [ 2400/ 6679]
2021-06-14 22:12:47,143 - INFO - loss: 1412.896606  [ 2560/ 6679]
2021-06-14 22:13:06,000 - INFO - loss: 1141.227905  [ 2720/ 6679]
2021-06-14 22:13:24,502 - INFO - loss: 915.961182  [ 2880/ 6679]
2021-06-14 22:13:43,359 - INFO - loss: 1219.768433  [ 3040/ 6679]
2021-06-14 22:14:00,959 - INFO - loss: 1290.063965  [ 3200/ 6679]
2021-06-14 22:14:21,573 - INFO - loss: 1347.186890  [ 3360/ 6679]
2021-06-14 22:14:42,842 - INFO - loss: 951.860901  [ 3520/ 6679]
2021-06-14 22:15:01,998 - INFO - loss: 1455.075195  [ 3680/ 6679]
2021-06-14 22:15:21,925 - INFO - loss: 1033.638916  [ 3840/ 6679]
2021-06-14 22:15:42,927 - INFO - loss: 837.104187  [ 4000/ 6679]
2021-06-14 22:16:02,947 - INFO - loss: 930.414673  [ 4160/ 6679]
2021-06-14 22:16:24,740 - INFO - loss: 599.078064  [ 4320/ 6679]
2021-06-14 22:16:48,130 - INFO - loss: 941.873962  [ 4480/ 6679]
2021-06-14 22:17:11,555 - INFO - loss: 904.252075  [ 4640/ 6679]
2021-06-14 22:17:37,310 - INFO - loss: 613.118774  [ 4800/ 6679]
2021-06-14 22:17:59,848 - INFO - loss: 914.119385  [ 4960/ 6679]
2021-06-14 22:18:19,497 - INFO - loss: 705.025574  [ 5120/ 6679]
2021-06-14 22:18:38,680 - INFO - loss: 605.849182  [ 5280/ 6679]
2021-06-14 22:18:59,797 - INFO - loss: 401.256348  [ 5440/ 6679]
2021-06-14 22:19:19,606 - INFO - loss: 464.379425  [ 5600/ 6679]
2021-06-14 22:19:43,914 - INFO - loss: 496.955200  [ 5760/ 6679]
2021-06-14 22:20:05,122 - INFO - loss: 363.315552  [ 5920/ 6679]
2021-06-14 22:20:24,865 - INFO - loss: 436.430298  [ 6080/ 6679]
2021-06-14 22:20:44,451 - INFO - loss: 347.264648  [ 6240/ 6679]
2021-06-14 22:21:02,700 - INFO - loss: 303.087891  [ 6400/ 6679]
2021-06-14 22:21:22,587 - INFO - loss: 277.932556  [ 6560/ 6679]
2021-06-14 22:22:44,289 - INFO - Validation Error: Accuracy: 24.2%, Avg loss: 0.356475 

2021-06-14 22:22:44,752 - INFO - Epoch 2
-------------------------------
2021-06-14 22:22:48,058 - INFO - loss: 215.588394  [    0/ 6679]
2021-06-14 22:23:07,746 - INFO - loss: 176.729660  [  160/ 6679]
2021-06-14 22:23:24,916 - INFO - loss: 212.669922  [  320/ 6679]
2021-06-14 22:23:37,546 - INFO - loss: 133.020370  [  480/ 6679]
2021-06-14 22:23:51,507 - INFO - loss: 164.577530  [  640/ 6679]
2021-06-14 22:24:07,999 - INFO - loss: 130.080780  [  800/ 6679]
2021-06-14 22:24:22,661 - INFO - loss: 124.847183  [  960/ 6679]
2021-06-14 22:24:41,846 - INFO - loss: 127.786766  [ 1120/ 6679]
2021-06-14 22:24:56,527 - INFO - loss: 120.827385  [ 1280/ 6679]
2021-06-14 22:25:11,722 - INFO - loss: 81.613449  [ 1440/ 6679]
2021-06-14 22:25:26,796 - INFO - loss: 102.004692  [ 1600/ 6679]
2021-06-14 22:25:39,722 - INFO - loss: 105.202461  [ 1760/ 6679]
2021-06-14 22:25:55,515 - INFO - loss: 84.867363  [ 1920/ 6679]
2021-06-14 22:26:14,240 - INFO - loss: 90.415291  [ 2080/ 6679]
2021-06-14 22:26:31,525 - INFO - loss: 71.585716  [ 2240/ 6679]
2021-06-14 22:26:47,393 - INFO - loss: 60.988922  [ 2400/ 6679]
2021-06-14 22:27:04,557 - INFO - loss: 63.147320  [ 2560/ 6679]
2021-06-14 22:27:24,964 - INFO - loss: 49.653465  [ 2720/ 6679]
2021-06-14 22:27:41,433 - INFO - loss: 59.995750  [ 2880/ 6679]
2021-06-14 22:27:54,994 - INFO - loss: 81.975220  [ 3040/ 6679]
2021-06-14 22:28:05,814 - INFO - loss: 53.483543  [ 3200/ 6679]
2021-06-14 22:28:19,858 - INFO - loss: 51.837288  [ 3360/ 6679]
2021-06-14 22:28:33,965 - INFO - loss: 67.309708  [ 3520/ 6679]
2021-06-14 22:28:48,319 - INFO - loss: 54.503605  [ 3680/ 6679]
2021-06-14 22:29:06,614 - INFO - loss: 44.763767  [ 3840/ 6679]
2021-06-14 22:29:19,472 - INFO - loss: 47.158478  [ 4000/ 6679]
2021-06-14 22:29:32,699 - INFO - loss: 43.738392  [ 4160/ 6679]
2021-06-14 22:29:50,832 - INFO - loss: 55.124187  [ 4320/ 6679]
2021-06-14 22:30:04,710 - INFO - loss: 32.237152  [ 4480/ 6679]
2021-06-14 22:30:18,369 - INFO - loss: 40.796566  [ 4640/ 6679]
2021-06-14 22:30:34,646 - INFO - loss: 39.960125  [ 4800/ 6679]
2021-06-14 22:30:49,161 - INFO - loss: 44.314529  [ 4960/ 6679]
2021-06-14 22:31:02,490 - INFO - loss: 32.478939  [ 5120/ 6679]
2021-06-14 22:31:17,697 - INFO - loss: 34.476326  [ 5280/ 6679]
2021-06-14 22:31:38,680 - INFO - loss: 29.669760  [ 5440/ 6679]
2021-06-14 22:31:53,662 - INFO - loss: 31.805372  [ 5600/ 6679]
2021-06-14 22:32:09,401 - INFO - loss: 33.556320  [ 5760/ 6679]
2021-06-14 22:32:23,597 - INFO - loss: 25.773300  [ 5920/ 6679]
2021-06-14 22:32:37,834 - INFO - loss: 27.677263  [ 6080/ 6679]
2021-06-14 22:32:51,980 - INFO - loss: 25.058605  [ 6240/ 6679]
2021-06-14 22:33:06,039 - INFO - loss: 20.883005  [ 6400/ 6679]
2021-06-14 22:33:24,948 - INFO - loss: 34.066227  [ 6560/ 6679]
2021-06-14 22:34:33,877 - INFO - Validation Error: Accuracy: 13.5%, Avg loss: 0.038559 

2021-06-14 22:34:34,310 - INFO - Epoch 3
-------------------------------
2021-06-14 22:34:38,720 - INFO - loss: 22.450254  [    0/ 6679]
2021-06-14 22:34:57,439 - INFO - loss: 22.272657  [  160/ 6679]
2021-06-14 22:35:12,203 - INFO - loss: 23.494211  [  320/ 6679]
2021-06-14 22:35:32,412 - INFO - loss: 16.460230  [  480/ 6679]
2021-06-14 22:35:47,661 - INFO - loss: 18.130451  [  640/ 6679]
2021-06-14 22:36:03,638 - INFO - loss: 25.634600  [  800/ 6679]
2021-06-14 22:36:18,115 - INFO - loss: 21.202429  [  960/ 6679]
2021-06-14 22:36:31,177 - INFO - loss: 24.218832  [ 1120/ 6679]
2021-06-14 22:36:42,565 - INFO - loss: 22.848980  [ 1280/ 6679]
2021-06-14 22:36:56,814 - INFO - loss: 18.547079  [ 1440/ 6679]
2021-06-14 22:37:08,490 - INFO - loss: 15.883520  [ 1600/ 6679]
2021-06-14 22:37:21,566 - INFO - loss: 18.190773  [ 1760/ 6679]
2021-06-14 22:37:42,825 - INFO - loss: 19.342447  [ 1920/ 6679]
2021-06-14 22:37:55,798 - INFO - loss: 13.556728  [ 2080/ 6679]
2021-06-14 22:38:13,078 - INFO - loss: 16.797983  [ 2240/ 6679]
2021-06-14 22:38:28,283 - INFO - loss: 12.564940  [ 2400/ 6679]
2021-06-14 22:38:46,373 - INFO - loss: 16.453905  [ 2560/ 6679]
2021-06-14 22:39:00,290 - INFO - loss: 16.302446  [ 2720/ 6679]
2021-06-14 22:39:15,846 - INFO - loss: 14.330383  [ 2880/ 6679]
2021-06-14 22:39:29,622 - INFO - loss: 17.788465  [ 3040/ 6679]
2021-06-14 22:39:41,813 - INFO - loss: 13.890695  [ 3200/ 6679]
2021-06-14 22:40:03,458 - INFO - loss: 10.549763  [ 3360/ 6679]
2021-06-14 22:40:17,141 - INFO - loss: 8.380800  [ 3520/ 6679]
2021-06-14 22:40:34,031 - INFO - loss: 11.733340  [ 3680/ 6679]
2021-06-14 22:40:49,935 - INFO - loss: 9.727752  [ 3840/ 6679]
2021-06-14 22:41:05,690 - INFO - loss: 11.341428  [ 4000/ 6679]
2021-06-14 22:41:19,444 - INFO - loss: 10.266891  [ 4160/ 6679]
2021-06-14 22:41:32,361 - INFO - loss: 14.781100  [ 4320/ 6679]
2021-06-14 22:41:46,199 - INFO - loss: 10.109798  [ 4480/ 6679]
2021-06-14 22:42:02,591 - INFO - loss: 11.181227  [ 4640/ 6679]
2021-06-14 22:42:18,183 - INFO - loss: 7.720846  [ 4800/ 6679]
2021-06-14 22:42:30,879 - INFO - loss: 10.767101  [ 4960/ 6679]
2021-06-14 22:42:45,170 - INFO - loss: 8.017028  [ 5120/ 6679]
2021-06-14 22:42:59,023 - INFO - loss: 8.965528  [ 5280/ 6679]
2021-06-14 22:43:11,926 - INFO - loss: 7.872854  [ 5440/ 6679]
2021-06-14 22:43:24,474 - INFO - loss: 11.248747  [ 5600/ 6679]
2021-06-14 22:43:35,626 - INFO - loss: 10.123695  [ 5760/ 6679]
2021-06-14 22:43:47,617 - INFO - loss: 9.631990  [ 5920/ 6679]
2021-06-14 22:44:01,572 - INFO - loss: 8.105742  [ 6080/ 6679]
2021-06-14 22:44:14,496 - INFO - loss: 8.283704  [ 6240/ 6679]
2021-06-14 22:44:27,960 - INFO - loss: 8.630737  [ 6400/ 6679]
2021-06-14 22:44:40,227 - INFO - loss: 7.663364  [ 6560/ 6679]
2021-06-14 22:45:42,523 - INFO - Validation Error: Accuracy: 6.0%, Avg loss: 0.010239 

2021-06-14 22:45:43,059 - INFO - Epoch 4
-------------------------------
2021-06-14 22:45:47,058 - INFO - loss: 6.557616  [    0/ 6679]
2021-06-14 22:46:02,796 - INFO - loss: 9.015849  [  160/ 6679]
2021-06-14 22:46:16,163 - INFO - loss: 8.988770  [  320/ 6679]
2021-06-14 22:46:30,915 - INFO - loss: 6.724934  [  480/ 6679]
2021-06-14 22:46:46,579 - INFO - loss: 7.625375  [  640/ 6679]
2021-06-14 22:47:02,043 - INFO - loss: 7.009772  [  800/ 6679]
2021-06-14 22:47:17,221 - INFO - loss: 5.934510  [  960/ 6679]
2021-06-14 22:47:31,399 - INFO - loss: 7.348708  [ 1120/ 6679]
2021-06-14 22:47:48,541 - INFO - loss: 7.391023  [ 1280/ 6679]
2021-06-14 22:48:02,415 - INFO - loss: 6.809557  [ 1440/ 6679]
2021-06-14 22:48:21,438 - INFO - loss: 6.193058  [ 1600/ 6679]
2021-06-14 22:48:38,468 - INFO - loss: 6.845460  [ 1760/ 6679]
2021-06-14 22:48:56,895 - INFO - loss: 6.062510  [ 1920/ 6679]
2021-06-14 22:49:16,984 - INFO - loss: 5.720495  [ 2080/ 6679]
2021-06-14 22:49:33,749 - INFO - loss: 5.838298  [ 2240/ 6679]
2021-06-14 22:49:49,895 - INFO - loss: 6.964474  [ 2400/ 6679]
2021-06-14 22:50:04,651 - INFO - loss: 5.456701  [ 2560/ 6679]
2021-06-14 22:50:19,193 - INFO - loss: 5.388610  [ 2720/ 6679]
2021-06-14 22:50:32,744 - INFO - loss: 5.743835  [ 2880/ 6679]
2021-06-14 22:50:48,592 - INFO - loss: 6.231894  [ 3040/ 6679]
2021-06-14 22:51:02,388 - INFO - loss: 5.485474  [ 3200/ 6679]
2021-06-14 22:51:16,652 - INFO - loss: 7.221633  [ 3360/ 6679]
2021-06-14 22:51:31,679 - INFO - loss: 6.653303  [ 3520/ 6679]
2021-06-14 22:51:45,061 - INFO - loss: 6.189264  [ 3680/ 6679]
